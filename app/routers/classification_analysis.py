import asyncio
import json
import logging
import os
import httpx
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from pathlib import Path
from fastapi import APIRouter, HTTPException, Query, BackgroundTasks
from langchain_core.messages import HumanMessage
from app.settings.auth import get_langchain_token, get_mongodb
from app.settings.paths import DB_NAME
from bson.objectid import ObjectId
from app.routers.calls import convert_date_string # –î–æ–±–∞–≤–ª–µ–Ω–æ
from app.services.recommendation_analysis_service import RecommendationAnalysisService
from app.models.call_analysis import CallScoresResponse, CriterionScore

router = APIRouter(tags=["Classification Call Analysis"])
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤
CLASSIFICATION_TEMPLATE = Path('app/data/prompts/classification_call.txt').read_text()
ANALYSIS_TEMPLATES = {
    1: Path('app/data/prompts/initial_call.txt').read_text(),
    2: Path('app/data/prompts/secondary_call.txt').read_text(),
    3: Path('app/data/prompts/re_call.txt').read_text(),
    4: Path('app/data/prompts/confirmation_call.txt').read_text(),
    5: Path('app/data/prompts/other_call.txt').read_text()
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChatGPT
llm = get_langchain_token()

async def wait_for_transcription_file(transcription_path: Path, max_wait_seconds: int = 60) -> bool:
    """
    –û–∂–∏–¥–∞–µ—Ç –ø–æ—è–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω, False –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è.
    """
    wait_interval = 5  # —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
    attempts = max_wait_seconds // wait_interval
    
    for attempt in range(attempts):
        if transcription_path.exists() and transcription_path.stat().st_size > 0:
            logger.info(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –Ω–∞–π–¥–µ–Ω: {transcription_path}")
            return True
        
        if attempt < attempts - 1:  # –Ω–µ –∂–¥–µ–º –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ø—ã—Ç–∫–∏
            logger.info(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤, –æ–∂–∏–¥–∞–Ω–∏–µ {wait_interval}—Å... (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{attempts})")
            await asyncio.sleep(wait_interval)
    
    logger.warning(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ {max_wait_seconds}—Å –æ–∂–∏–¥–∞–Ω–∏—è: {transcription_path}")
    return False

@router.post("/api/call/analyze-call-new/{call_id}")
async def analyze_call_type(call_id: str) -> Dict[str, Any]:
    
    """–ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ –∑–≤–æ–Ω–∫–∞ –∏ –µ–≥–æ –º–µ—Ç—Ä–∏–∫"""
    try:
        
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB
        client = get_mongodb()
        db = client[DB_NAME]
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–∞
        call = await db.calls.find_one({"_id": ObjectId(call_id)})
        if not call:
            raise HTTPException(status_code=404, detail="Call not found")

        # –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω–≤–µ—Ä—Å–∏—é –∏–∑ AmoCRM (–ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º AI-–∞–Ω–∞–ª–∏–∑–æ–º!)
        amocrm_conversion = call.get("metrics", {}).get("conversion")
        amocrm_conversion_type = call.get("conversion_type")
        amocrm_duration = call.get("metrics", {}).get("duration")
        logger.info(f"üíæ [Preserve AmoCRM Data] conversion={amocrm_conversion}, type={amocrm_conversion_type}, duration={amocrm_duration}")

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–∞
        transcription_path = Path('app/data/transcription') / call['filename_transcription']
        
        # –û–∂–∏–¥–∞–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–æ 60 —Å–µ–∫—É–Ω–¥
        if not await wait_for_transcription_file(transcription_path, max_wait_seconds=60):
            raise HTTPException(status_code=404, detail="Transcription file not found")
            
        transcription = transcription_path.read_text(encoding='utf-8')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChatGPT
        llm = get_langchain_token()
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–≤–æ–Ω–∫–∞
        classification_message = HumanMessage(content=CLASSIFICATION_TEMPLATE.format(transcription=transcription))
        call_type_response = llm.invoke([classification_message])
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç markdown-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            content = call_type_response.content
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()
                
            call_type = json.loads(content)
            logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –∑–≤–æ–Ω–∫–∞: {call_type}")
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {call_type_response.content}")
            raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–∏–ø–∞ –∑–≤–æ–Ω–∫–∞")
        
        # –ê–Ω–∞–ª–∏–∑ –∑–≤–æ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ —Ç–∏–ø–∞
        template = ANALYSIS_TEMPLATES[call_type['call_type_id']]
        # –í–ê–ñ–ù–û: –ü–µ—Ä–µ–¥–∞–µ–º conversion –≤ –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ overall_score
        patient_booking_value = "true" if amocrm_conversion else "false"
        analysis_message = HumanMessage(content=template.format(
            transcription=transcription,
            patient_booking=patient_booking_value
        ))
        analysis_response = llm.invoke([analysis_message])
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç markdown-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            content = analysis_response.content
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()
                
            analysis_results = json.loads(content)
            logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞: {analysis_response.content}")
            raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–≤–æ–Ω–∫–∞")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        metrics = {}
        recommendations = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        for key, data in analysis_results.items():
            if isinstance(data, dict) and 'score' in data:
                metrics[key] = data['score']
            elif key == 'recommendations':
                recommendations = data
            elif key == 'overall_score':
                # overall_score - —ç—Ç–æ float, –∞ –Ω–µ dict
                metrics[key] = data

        # –î–ª—è —Ç–∏–ø–∞ "–¥—Ä—É–≥–æ–µ" –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å overall_score - –¥–æ–±–∞–≤–ª—è–µ–º 0
        if 'overall_score' not in metrics:
            metrics['overall_score'] = 0.0
            logger.info(f"–¢–∏–ø –∑–≤–æ–Ω–∫–∞ '{call_type['call_type']}' –Ω–µ –∏–º–µ–µ—Ç overall_score - —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 0.0")

        # –í–ê–ñ–ù–û: –ë–∏–Ω–∞—Ä–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å—Ç—Ä–æ–≥–æ 0 –∏–ª–∏ 10
        # AI –∏–Ω–æ–≥–¥–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ —Å—Ç–∞–≤–∏—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        binary_criteria = ['appointment', 'patient_booking', 'clinic_address', 'passport']
        for criterion in binary_criteria:
            if criterion in metrics:
                # –û–∫—Ä—É–≥–ª—è–µ–º: < 5 -> 0, >= 5 -> 10
                original_value = metrics[criterion]
                metrics[criterion] = 10 if original_value >= 5 else 0
                if original_value not in [0, 10]:
                    logger.warning(f"üîß [Binary Fix] {criterion}: {original_value} -> {metrics[criterion]}")

        # –í–ê–ñ–ù–û: patient_booking –í–°–ï–ì–î–ê –±–µ—Ä–µ–º –∏–∑ AmoCRM conversion, –ù–ï –æ—Ç AI!
        if amocrm_conversion is not None:
            metrics['patient_booking'] = 10 if amocrm_conversion else 0
            logger.info(f"‚úÖ [Override patient_booking] AmoCRM conversion={amocrm_conversion} -> patient_booking={metrics['patient_booking']}")

        # –í–ê–ñ–ù–û: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Å–∏—é –∏–∑ AmoCRM (–ù–ï –∏–∑ AI!)
        if amocrm_conversion is not None:
            metrics['conversion'] = amocrm_conversion
            logger.info(f"‚úÖ [Restore AmoCRM Conversion] metrics.conversion={amocrm_conversion}")

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º duration
        if amocrm_duration is not None:
            metrics['duration'] = amocrm_duration

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø –∑–≤–æ–Ω–∫–∞
        metrics['call_type_classification'] = call_type['call_type']
        
        # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∞–Ω–∞–ª–∏–∑–∞
        analysis_filename = f"{call['phone']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_analysis.txt"
        analysis_path = f"/app/app/data/analysis/{analysis_filename}"
        
        # –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–≤–æ–¥–∞ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª –∞–Ω–∞–ª–∏–∑–∞
        metrics_translation = {
            'greeting': '–ü–†–ò–í–ï–¢–°–¢–í–ò–ï',
            'patient_name': '–ò–ú–Ø –ü–ê–¶–ò–ï–ù–¢–ê',
            'needs_identification': '–í–´–Ø–í–õ–ï–ù–ò–ï –ü–û–¢–†–ï–ë–ù–û–°–¢–ï–ô',
            'service_presentation': '–ü–†–ï–ó–ï–ù–¢–ê–¶–ò–Ø –£–°–õ–£–ì',
            'clinic_presentation': '–ü–†–ï–ó–ï–ù–¢–ê–¶–ò–Ø –ö–õ–ò–ù–ò–ö–ò',
            'doctor_presentation': '–ü–†–ï–ó–ï–ù–¢–ê–¶–ò–Ø –í–†–ê–ß–ê',
            'patient_booking': '–ó–ê–ü–ò–°–¨ –ü–ê–¶–ò–ï–ù–¢–ê',
            'clinic_address': '–ê–î–†–ï–° –ö–õ–ò–ù–ò–ö–ò',
            'passport': '–ü–ê–°–ü–û–†–¢',
            'price': '–¶–ï–ù–ê',
            'expertise': '–≠–ö–°–ü–ï–†–¢–ù–û–°–¢–¨',
            'next_step': '–°–õ–ï–î–£–Æ–©–ò–ô –®–ê–ì',
            'appointment': '–ó–ê–ü–ò–°–¨',
            'emotional_tone': '–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–´–ô –¢–û–ù',
            'speech': '–†–ï–ß–¨',
            'initiative': '–ò–ù–ò–¶–ò–ê–¢–ò–í–ù–û–°–¢–¨'
        }
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è —Ñ–∞–π–ª–∞
        analysis_content = []
        analysis_content.append(f"# –ê–Ω–∞–ª–∏–∑ –∑–≤–æ–Ω–∫–∞ {call['phone']}\n\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        analysis_content.append("## –ú–ï–¢–ê–î–ê–ù–ù–´–ï\n")
        analysis_content.append(f"–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        analysis_content.append(f"–ö–ª–∏–Ω–∏–∫–∞: {call.get('subdomain', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}\n")
        analysis_content.append(f"–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä: {call.get('administrator', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n")
        analysis_content.append(f"–ö–æ–Ω—Ç–∞–∫—Ç: {call.get('contact_name', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n")
        analysis_content.append(f"Note ID: {call.get('note_id', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n")
        analysis_content.append(f"Contact ID: {call.get('contact_id', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n")
        analysis_content.append(f"Lead ID: {call.get('lead_id', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n\n")
        
        analysis_content.append(f"## –¢–∏–ø –∑–≤–æ–Ω–∫–∞: {call_type['call_type']}\n")
        analysis_content.append(f"–û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {call_type['explanation']}\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        for key, data in analysis_results.items():
            if isinstance(data, dict) and 'score' in data:
                metric_name = metrics_translation.get(key, key.upper())
                analysis_content.append(f"\n### {metric_name} (0-10 –±–∞–ª–ª–æ–≤)\n")
                analysis_content.append(f"**–û—Ü–µ–Ω–∫–∞: {data['score']}/10**\n")
                analysis_content.append(f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {data['comment']}\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        analysis_content.append(f"\n## –û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏\n")

        # –î–ª—è —Ç–∏–ø–∞ "–¥—Ä—É–≥–æ–µ" –Ω–µ—Ç overall_score (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ/–Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∑–≤–æ–Ω–∫–∏)
        if 'overall_score' in analysis_results:
            analysis_content.append(f"* –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {analysis_results['overall_score']:.2f}\n")
        else:
            # –î–ª—è —Ç–∏–ø–∞ "–¥—Ä—É–≥–æ–µ" —Å—Ç–∞–≤–∏–º 0 –∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            logger.info(f"–¢–∏–ø –∑–≤–æ–Ω–∫–∞ '{call_type['call_type']}' –Ω–µ –∏–º–µ–µ—Ç overall_score - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            analysis_content.append(f"* –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: –ù–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ (—Ç–∏–ø '{call_type['call_type']}')\n")

        # –ö–æ–Ω–≤–µ—Ä—Å–∏—è –±–µ—Ä–µ—Ç—Å—è –∏–∑ AmoCRM, –∞ –ù–ï –∏–∑ AI –∞–Ω–∞–ª–∏–∑–∞
        analysis_content.append(f"* –ö–æ–Ω–≤–µ—Ä—Å–∏—è (–∏–∑ AmoCRM): {'–î–∞' if amocrm_conversion else '–ù–µ—Ç'}\n")

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if 'recommendations' in analysis_results and analysis_results['recommendations']:
            analysis_content.append(f"\n## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n")
            for rec in analysis_results['recommendations']:
                analysis_content.append(f"* {rec}\n")
        else:
            logger.info(f"–¢–∏–ø –∑–≤–æ–Ω–∫–∞ '{call_type['call_type']}' –Ω–µ –∏–º–µ–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open(analysis_path, 'w', encoding='utf-8') as f:
            f.writelines(analysis_content)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ MongoDB
        update_data = {
            "metrics": metrics,
            "recommendations": recommendations,
            "analysis_id": analysis_filename,
            "analyzed_at": datetime.now(),
            "call_type_id": call_type['call_type_id'],
            "call_type_name": call_type['call_type'],
            "analyze_status": "success"
        }

        # –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º conversion_type –∏–∑ AmoCRM (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if amocrm_conversion_type:
            update_data["conversion_type"] = amocrm_conversion_type
            logger.info(f"‚úÖ [Restore AmoCRM] conversion_type={amocrm_conversion_type}")

        await db.calls.update_one(
            {"_id": ObjectId(call_id)},
            {"$set": update_data}
        )
        logger.info(f"üíæ [Save to DB] call_id={call_id}, metrics.conversion={metrics.get('conversion')}, conversion_type={update_data.get('conversion_type')}")

        return {
            "success": True,
            "call_id": call_id,
            "call_type": call_type,
            "analysis_results": analysis_results
        }
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON parsing error: {str(e)}")
        raise HTTPException(status_code=500, detail="Error parsing AI response")
        
    except Exception as e:
        logger.error(f"Error processing call analysis: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/api/analyze-by-date-range", summary="–ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∑–≤–æ–Ω–∫–æ–≤ –∑–∞ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç")
async def analyze_calls_by_date_range(
    background_tasks: BackgroundTasks,
    start_date_str: str = Query(..., description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD)"),
    end_date_str: str = Query(..., description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD)"),
    client_id: Optional[str] = Query(None, description="ID –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∑–≤–æ–Ω–∫–æ–≤ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)"),
    force_analyze: bool = Query(False, description="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–≤–æ–Ω–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –±—ã–ª–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –º–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∑–≤–æ–Ω–∫–æ–≤ –∏–∑ MongoDB –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç.
    –ó–≤–æ–Ω–∫–∏ –æ—Ç–±–∏—Ä–∞—é—Ç—Å—è –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (`created_date_for_filtering`), –Ω–∞–ª–∏—á–∏—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ 
    –∏, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ `client_id`.
    –ï—Å–ª–∏ `force_analyze`=False, —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∏ (–∏–º–µ—é—â–∏–µ `analysis_id`) –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è.
    –ó–∞–¥–∞—á–∏ –Ω–∞ –∞–Ω–∞–ª–∏–∑ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ —Ñ–æ–Ω.
    """
    logger.info(
        f"–ó–∞–ø—Ä–æ—Å –Ω–∞ –º–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑: {start_date_str} - {end_date_str}, client_id: {client_id}, "
        f"force_analyze: {force_analyze}"
    )

    start_time_global = datetime.now()

    start_date_obj = convert_date_string(start_date_str)
    end_date_obj = convert_date_string(end_date_str)

    if not start_date_obj or not end_date_obj:
        raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD.")

    if start_date_obj > end_date_obj:
        raise HTTPException(status_code=400, detail="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–∑–∂–µ –∫–æ–Ω–µ—á–Ω–æ–π –¥–∞—Ç—ã.")

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –ø–æ–ª—é "created_date_for_filtering"
    start_date_filter_str = start_date_obj.strftime("%Y-%m-%d")
    end_date_filter_str = end_date_obj.strftime("%Y-%m-%d")
    
    mongo_query = {
        "created_date_for_filtering": {"$gte": start_date_filter_str, "$lte": end_date_filter_str},
        "filename_transcription": {"$exists": True, "$ne": None, "$ne": ""} 
    }

    if client_id:
        mongo_query["client_id"] = client_id

    if not force_analyze:
        mongo_query["$or"] = [
            {"analysis_id": {"$exists": False}},
            {"analysis_id": None},
            {"analysis_id": ""}
        ]
        
    mongo_client = get_mongodb()
    db = mongo_client[DB_NAME]
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ _id –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    calls_to_analyze_cursor = db.calls.find(mongo_query, {"_id": 1})
    calls_to_analyze_list = await calls_to_analyze_cursor.to_list(length=None) 

    if not calls_to_analyze_list:
        logger.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–≤–æ–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.")
        return {
            "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–≤–æ–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
            "total_found": 0,
            "tasks_queued": 0,
            "duration_seconds": (datetime.now() - start_time_global).total_seconds()
        }

    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(calls_to_analyze_list)} –∑–≤–æ–Ω–∫–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞.")

    tasks_queued_count = 0
    
    for call_doc in calls_to_analyze_list:
        call_id_str = str(call_doc["_id"])
        try:
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –∞–Ω–∞–ª–∏–∑ –¥–ª—è call_id: {call_id_str}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é analyze_call_type –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            background_tasks.add_task(analyze_call_type, call_id=call_id_str)
            tasks_queued_count += 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –∞–Ω–∞–ª–∏–∑ –¥–ª—è call_id {call_id_str}: {e}")

    duration = (datetime.now() - start_time_global).total_seconds()
    logger.info(f"–ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑: {tasks_queued_count} –∑–∞–¥–∞—á –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Ñ–æ–Ω. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏: {duration:.2f} —Å–µ–∫.")

    return {
        "message": f"{tasks_queued_count} –∑–∞–¥–∞—á –Ω–∞ –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º.",
        "total_found": len(calls_to_analyze_list),
        "tasks_queued": tasks_queued_count,
        "duration_seconds": duration
    }


@router.get("/api/analyze-by-date-range-status")
async def get_analysis_status_by_date_range(
    start_date_str: str = Query(..., description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD)"),
    end_date_str: str = Query(..., description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD)"),
    client_id: Optional[str] = Query(None, description="ID –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∑–≤–æ–Ω–∫–æ–≤")
) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞ –∑–≤–æ–Ω–∫–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞.
    """
    try:
        start_date_obj = convert_date_string(start_date_str)
        end_date_obj = convert_date_string(end_date_str)

        if not start_date_obj or not end_date_obj:
            raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD.")

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        start_date_filter_str = start_date_obj.strftime("%Y-%m-%d")
        end_date_filter_str = end_date_obj.strftime("%Y-%m-%d")
        
        query = {
            "created_date_for_filtering": {"$gte": start_date_filter_str, "$lte": end_date_filter_str},
            "filename_transcription": {"$exists": True, "$ne": None, "$ne": ""} 
        }

        if client_id:
            query["client_id"] = client_id

        mongo_client = get_mongodb()
        db = mongo_client[DB_NAME]
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–≤–æ–Ω–∫–∏ —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è–º–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
        calls_cursor = db.calls.find(query)
        calls = await calls_cursor.to_list(length=None)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º –∞–Ω–∞–ª–∏–∑–∞
        total_calls = len(calls)
        processing_count = 0
        success_count = 0
        failed_count = 0
        pending_count = 0

        for call in calls:
            analyze_status = call.get("analyze_status", "pending")
            if analyze_status == "processing":
                processing_count += 1
            elif analyze_status == "success":
                success_count += 1
            elif analyze_status == "failed":
                failed_count += 1
            else:
                pending_count += 1

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ü–µ—Å—Å–∞
        if processing_count > 0:
            overall_status = "processing"
        elif pending_count > 0:
            overall_status = "pending"
        elif total_calls == success_count:
            overall_status = "completed"
        else:
            overall_status = "partial"

        return {
            "overall_status": overall_status,
            "total_calls": total_calls,
            "status_breakdown": {
                "pending": pending_count,
                "processing": processing_count,
                "success": success_count,
                "failed": failed_count
            },
            "progress_percentage": round((success_count / total_calls * 100), 2) if total_calls > 0 else 0
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")


@router.post("/api/recommendations/analyze-monthly")
async def analyze_monthly_recommendations(
    client_id: str = Query(..., description="ID –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"),
    year: int = Query(..., description="–ì–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2025)"),
    month: int = Query(..., ge=1, le=12, description="–ú–µ—Å—è—Ü (1-12)"),
    force_refresh: bool = Query(False, description="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—ç—à)"),
) -> Dict[str, Any]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ú–ï–°–Ø–ß–ù–´–ô –∞–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–¥–µ–ª—å–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤.
    
    –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –≤—Å–µ –Ω–µ–¥–µ–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –º–µ—Å—è—Ü –∏ —Å–æ–∑–¥–∞—ë—Ç:
    - –°–≤–æ–¥–∫—É –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤ –∑–∞ –º–µ—Å—è—Ü
    - –í—ã–¥–µ–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º (–ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∏–∑ –Ω–µ–¥–µ–ª–∏ –≤ –Ω–µ–¥–µ–ª—é)
    - –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—ç—à–∏—Ä—É—é—Ç—Å—è —Å period_type='monthly'. 
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ force_refresh=true –¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    """
    logger.info(
        f"–ó–∞–ø—Ä–æ—Å –Ω–∞ –º–µ—Å—è—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: client_id={client_id}, "
        f"–ø–µ—Ä–∏–æ–¥: {month}/{year}, force_refresh={force_refresh}"
    )

    try:
        service = RecommendationAnalysisService(client_id=client_id)
        
        if force_refresh:
            logger.info("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Å—è—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (force_refresh=True)")
            analysis_result = await service.analyze_monthly_force_refresh(year=year, month=month)
        else:
            analysis_result = await service.analyze_monthly_recommendations(year=year, month=month)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞
        try:
            async with httpx.AsyncClient(timeout=None) as client:
                postgres_sync_url = f"{os.getenv('API_BASE_URL', 'http://localhost:8001/api')}/postgres/sync-now"
                headers = {"X-API-Key": os.getenv("API_KEY", "")}
                logger.info("–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL –ø–æ—Å–ª–µ –º–µ—Å—è—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                postgres_response = await client.post(postgres_sync_url, headers=headers)
                if postgres_response.status_code == 200:
                    logger.info("–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è PostgreSQL —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–∞")
                else:
                    logger.warning(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–ø—É—Å–∫–æ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL: {postgres_response.status_code}")
        except Exception as postgres_error:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL: {postgres_error}")
        
        # –ù–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤
        month_names = {
            1: "–Ø–Ω–≤–∞—Ä—å", 2: "–§–µ–≤—Ä–∞–ª—å", 3: "–ú–∞—Ä—Ç", 4: "–ê–ø—Ä–µ–ª—å",
            5: "–ú–∞–π", 6: "–ò—é–Ω—å", 7: "–ò—é–ª—å", 8: "–ê–≤–≥—É—Å—Ç",
            9: "–°–µ–Ω—Ç—è–±—Ä—å", 10: "–û–∫—Ç—è–±—Ä—å", 11: "–ù–æ—è–±—Ä—å", 12: "–î–µ–∫–∞–±—Ä—å"
        }
        
        return {
            "message": f"–ú–µ—Å—è—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞ {month_names[month]} {year} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.",
            "period": f"{month_names[month]} {year}",
            "period_type": "monthly",
            "data": analysis_result
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–µ—Å—è—á–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è client_id {client_id}: {e}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")


@router.post("/api/recommendations/analyze-by-date-range")
async def analyze_recommendations_by_date_range(
    client_id: str = Query(..., description="ID –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"),
    start_date_str: str = Query(..., description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD"),
    end_date_str: str = Query(..., description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD"),
    force_refresh: bool = Query(False, description="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—ç—à)"),
) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏ –æ–±–æ–±—â–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥.
    
    –í–ê–ñ–ù–û: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ç–µ–ø–µ—Ä—å —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –ë–ê–õ–õ–û–í –∏–∑ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã:
    - –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Å –±–∞–ª–ª–∞–º–∏ 8-10
    - –ó–æ–Ω—ã —Ä–æ—Å—Ç–∞: –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Å –±–∞–ª–ª–∞–º–∏ 5-7
    - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞: –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Å –±–∞–ª–ª–∞–º–∏ 0-4
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—ç—à–∏—Ä—É—é—Ç—Å—è. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ force_refresh=true –¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    """
    logger.info(
        f"–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: client_id={client_id}, "
        f"–ø–µ—Ä–∏–æ–¥ —Å {start_date_str} –ø–æ {end_date_str}, force_refresh={force_refresh}"
    )

    start_date_obj = convert_date_string(start_date_str)
    end_date_obj = convert_date_string(end_date_str)

    if not start_date_obj or not end_date_obj:
        raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD.")

    if start_date_obj > end_date_obj:
        raise HTTPException(status_code=400, detail="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–∑–∂–µ –∫–æ–Ω–µ—á–Ω–æ–π –¥–∞—Ç—ã.")

    # –°–µ—Ä–≤–∏—Å –æ–∂–∏–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã date, –∞ –Ω–µ datetime
    start_date_val = start_date_obj.date()
    end_date_val = end_date_obj.date()

    try:
        service = RecommendationAnalysisService(client_id=client_id)
        
        # –ï—Å–ª–∏ force_refresh=True, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
        if force_refresh:
            logger.info("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ (force_refresh=True)")
            analysis_result = await service.analyze_recommendations_force_refresh(
                start_date=start_date_val,
                end_date=end_date_val
            )
        else:
            analysis_result = await service.analyze_recommendations_for_period(
                start_date=start_date_val,
                end_date=end_date_val
            )
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞
        try:
            async with httpx.AsyncClient(timeout=None) as client:  # –ë–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö
                # URL –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL
                postgres_sync_url = f"{os.getenv('API_BASE_URL', 'http://localhost:8001/api')}/postgres/sync-now"
                headers = {"X-API-Key": os.getenv("API_KEY", "")}
                logger.info("–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                postgres_response = await client.post(postgres_sync_url, headers=headers)
                if postgres_response.status_code == 200:
                    logger.info("–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è PostgreSQL —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–∞")
                else:
                    logger.warning(f"–ü—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–ø—É—Å–∫–æ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL: {postgres_response.status_code}")
        except Exception as postgres_error:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ PostgreSQL: {postgres_error}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        
        return {
            "message": "–ê–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.",
            "data": analysis_result
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è client_id {client_id}: {e}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")


@router.get("/api/recommendations/analyze-by-date-range-status")
async def get_recommendations_analysis_status_by_date_range(
    client_id: str = Query(..., description="ID –∫–ª–∏–µ–Ω—Ç–∞"),
    start_date_str: str = Query(..., description="–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD"),
    end_date_str: str = Query(..., description="–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD"),
) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞.
    """
    try:
        start_date_obj = convert_date_string(start_date_str)
        end_date_obj = convert_date_string(end_date_str)

        if not start_date_obj or not end_date_obj:
            raise HTTPException(status_code=400, detail="–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD.MM.YYYY –∏–ª–∏ YYYY-MM-DD.")

        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        mongo_client = get_mongodb()
        db = mongo_client[DB_NAME]
        analysis_collection = db["recommendation_analysis"]
        
        # –ò—â–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        start_date_val = start_date_obj.date()
        end_date_val = end_date_obj.date()
        
        cache_query = {
            "client_id": client_id,
            "start_date": start_date_val.isoformat(),
            "end_date": end_date_val.isoformat()
        }
        
        cached_result = await analysis_collection.find_one(cache_query)
        
        if cached_result:
            # –ê–Ω–∞–ª–∏–∑ —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω
            summary_analyze_status = cached_result.get("summary_analyze_status", "success")
            return {
                "overall_status": "completed",
                "summary_analyze_status": summary_analyze_status,
                "has_cached_result": True,
                "cache_created_at": cached_result.get("created_at"),
                "analysis_available": True
            }
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–≤–æ–Ω–∫–∏ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            calls_query = {
                "client_id": client_id,
                "created_date_for_filtering": {
                    "$gte": start_date_val.isoformat(),
                    "$lte": end_date_val.isoformat()
                },
                "recommendations": {"$exists": True, "$ne": []}
            }
            
            calls_cursor = db.calls.find(calls_query, {"_id": 1})
            calls_with_recommendations = await calls_cursor.to_list(length=None)
            
            if not calls_with_recommendations:
                return {
                    "overall_status": "no_data",
                    "summary_analyze_status": "not_applicable",
                    "has_cached_result": False,
                    "calls_with_recommendations": 0,
                    "analysis_available": False,
                    "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–≤–æ–Ω–∫–æ–≤ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"
                }
            
            return {
                "overall_status": "pending",
                "summary_analyze_status": "pending",
                "has_cached_result": False,
                "calls_with_recommendations": len(calls_with_recommendations),
                "analysis_available": False,
                "message": "–ê–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –µ—â–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞"
            }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")


@router.get("/api/call/scores", response_model=CallScoresResponse, summary="–ü–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫–∏ –∑–≤–æ–Ω–∫–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º")
async def get_call_scores(
    note_id: int = Query(..., description="ID –∑–∞–º–µ—Ç–∫–∏ –≤ AmoCRM"),
    client_id: Optional[str] = Query(None, description="ID –∫–ª–∏–Ω–∏–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏)")
) -> CallScoresResponse:
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫–∏ –∑–≤–æ–Ω–∫–∞ –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –∏–∑ –Ω–æ–≤–æ–π —à–∫–∞–ª—ã –æ—Ü–µ–Ω–æ–∫.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –û—Ü–µ–Ω–∫–∏ –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º (0-10 –±–∞–ª–ª–æ–≤)
    - –û–±—â—É—é –æ—Ü–µ–Ω–∫—É (overall_score)
    - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
    - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

    –¢–∏–ø—ã –∑–≤–æ–Ω–∫–æ–≤ –∏ –∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏–∏:
    - **–ü–µ—Ä–≤–∏—á–∫–∞** (17 –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤): –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞, –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è —É—Å–ª—É–≥–∏/–∫–ª–∏–Ω–∏–∫–∏/–≤—Ä–∞—á–∞, –∑–∞–ø–∏—Å—å, —Ü–µ–Ω–∞, —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç—å, —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥, –∑–∞–ø–∏—Å—å –Ω–∞ –ø—Ä–∏–µ–º, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–∫—Ä–∞—Å, —Ä–µ—á—å, –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞, –∞–¥—Ä–µ—Å, –ø–∞—Å–ø–æ—Ä—Ç, —Ä–∞–±–æ—Ç–∞ —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏
    - **–í—Ç–æ—Ä–∏—á–∫–∞** (10 –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤): –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞, –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π, —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç—å, —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥, –∑–∞–ø–∏—Å—å –Ω–∞ –ø—Ä–∏–µ–º, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–∫—Ä–∞—Å, —Ä–µ—á—å, –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞, —Ä–∞–±–æ—Ç–∞ —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏
    - **–ü–µ—Ä–µ–∑–≤–æ–Ω** (9 –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤): –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –∏–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞, –∞–ø–µ–ª–ª—è—Ü–∏—è, —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥, –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞, —Ä–µ—á—å, –∞–¥—Ä–µ—Å, –ø–∞—Å–ø–æ—Ä—Ç, —Ä–∞–±–æ—Ç–∞ —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏
    """
    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB
        mongo_client = get_mongodb()
        db = mongo_client[DB_NAME]

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        query = {"note_id": note_id}
        if client_id:
            query["client_id"] = client_id

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–≤–æ–Ω–∫–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        call = await db.calls.find_one(query)

        if not call:
            raise HTTPException(
                status_code=404,
                detail=f"–ó–≤–æ–Ω–æ–∫ —Å note_id={note_id}" + (f" –∏ client_id={client_id}" if client_id else "") + " –Ω–µ –Ω–∞–π–¥–µ–Ω"
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∞–Ω–∞–ª–∏–∑–∞
        if not call.get("metrics") or not call.get("analyze_status") == "success":
            raise HTTPException(
                status_code=404,
                detail=f"–ó–≤–æ–Ω–æ–∫ —Å note_id={note_id} –µ—â–µ –Ω–µ –±—ã–ª –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ /api/call/analyze-call-new/{call['_id']}"
            )

        # –ú–∞–ø–ø–∏–Ω–≥ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –Ω–∞ —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        CRITERIA_NAMES = {
            "greeting": "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ",
            "patient_name": "–ò–º—è –ø–∞—Ü–∏–µ–Ω—Ç–∞",
            "needs_identification": "–í—ã—è–≤–ª–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π",
            "objection_handling": "–†–∞–±–æ—Ç–∞ —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏",
            "service_presentation": "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è —É—Å–ª—É–≥–∏",
            "clinic_presentation": "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –∫–ª–∏–Ω–∏–∫–∏",
            "doctor_presentation": "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –≤—Ä–∞—á–∞",
            "patient_booking": "–ó–∞–ø–∏—Å—å –ø–∞—Ü–∏–µ–Ω—Ç–∞",
            "clinic_address": "–ê–¥—Ä–µ—Å –∫–ª–∏–Ω–∏–∫–∏",
            "passport": "–ü–∞—Å–ø–æ—Ä—Ç",
            "price": "–¶–µ–Ω–∞",
            "expertise": "–≠–∫—Å–ø–µ—Ä—Ç–Ω–æ—Å—Ç—å",
            "next_step": "–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥",
            "appointment": "–ó–∞–ø–∏—Å—å –Ω–∞ –ø—Ä–∏–µ–º",
            "emotional_tone": "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–∫—Ä–∞—Å",
            "speech": "–†–µ—á—å",
            "initiative": "–ò–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞",
            "appeal": "–ê–ø–µ–ª–ª—è—Ü–∏—è"
        }

        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –∑–≤–æ–Ω–∫–∞
        metrics = call.get("metrics", {})

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫–∏ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        scores = {}
        for criterion_key, criterion_value in metrics.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ-—á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if criterion_key in ["conversion", "duration", "call_type_classification", "overall_score"]:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —á–∏—Å–ª–æ
            if isinstance(criterion_value, (int, float)):
                criterion_name = CRITERIA_NAMES.get(criterion_key, criterion_key.replace("_", " ").title())
                scores[criterion_key] = CriterionScore(
                    name=criterion_name,
                    score=int(criterion_value),
                    comment=None  # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑ —Ñ–∞–π–ª–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                )

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        transcription_url = None
        if call.get("filename_transcription"):
            transcription_url = f"/api/transcriptions/{call.get('filename_transcription')}/download"

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = CallScoresResponse(
            note_id=call.get("note_id"),
            client_id=call.get("client_id"),
            call_type=call.get("call_type_name", "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"),
            call_type_id=call.get("call_type_id"),
            administrator=call.get("administrator"),
            created_date=call.get("created_date_for_filtering"),
            overall_score=metrics.get("overall_score"),
            conversion=metrics.get("conversion"),
            scores=scores,
            recommendations=call.get("recommendations", []),
            transcription_url=transcription_url
        )

        logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∑–≤–æ–Ω–∫–∞ note_id={note_id}, —Ç–∏–ø={response.call_type}")
        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ü–µ–Ω–æ–∫ –∑–≤–æ–Ω–∫–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")
